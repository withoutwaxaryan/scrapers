{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.magicbricks.com/independent-house-for-rent-in-new-delhi-pppfr\n",
    "    \n",
    "https://www.magicbricks.com/property-for-rent-in-new-delhi-pppfr\n",
    "    \n",
    "https://www.magicbricks.com/flats-for-rent-in-new-delhi-pppfr\n",
    "\n",
    "You cant use the rooms having magicbricks exclusive written\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup, Comment\n",
    "import requests\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = [\n",
    "'Rajkot',\n",
    "'Anand',\n",
    "'Bangalore',\n",
    "'Chennai',\n",
    "'Ahmedabad',\n",
    "'Noida',\n",
    "'Faridabad',\n",
    "'Mumbai',\n",
    "'Hyderabad',\n",
    "'Navi-Mumbai',\n",
    "'Gurgaon',\n",
    "'Greater-Noida',\n",
    "'Pune',\n",
    "'Kolkata',\n",
    "'Thane',\n",
    "'Ghaziabad',\n",
    "'New-Delhi',\n",
    "'Agra',\n",
    "'Durgapur',\n",
    "'Kochi',\n",
    "'Palghar',\n",
    "'Trichy',\n",
    "'Allahabad',\n",
    "'Goa',\n",
    "'Kottayam',\n",
    "'Patna',\n",
    "'Udaipur',\n",
    "'Aurangabad',\n",
    "'Gorakhpur',\n",
    "'Kozhikode',\n",
    "'Rajahmundry',\n",
    "'Udupi',\n",
    "'Bhiwadi',\n",
    "'Guntur',\n",
    "'Lucknow',\n",
    "'Ranchi',\n",
    "'Vadodara',\n",
    "'Bhopal',\n",
    "'Guwahati',\n",
    "'Madurai',\n",
    "'Raipur',\n",
    "'Vapi',\n",
    "'Bhubaneswar',\n",
    "'Haridwar',\n",
    "'Mangalore',\n",
    "'Salem',\n",
    "'Varanasi',\n",
    "'Bokaro-Steel-City',\n",
    "'Indore',\n",
    "'Gwalior',\n",
    "'Sonipat',\n",
    "'Vijayawada',\n",
    "'Chandigarh',\n",
    "'Jaipur',\n",
    "'Mysore',\n",
    "'Surat',\n",
    "'Visakhapatnam',\n",
    "'Coimbatore',\n",
    "'Jamshedpur',\n",
    "'Nagpur',\n",
    "'Thrissur',\n",
    "'Ahmadnagar',\n",
    "'Dehradun',\n",
    "'Jodhpur',\n",
    "'Nashik',\n",
    "'Tirupati',\n",
    "'Kanpur',\n",
    "'Navsari',\n",
    "'Trivandrum',]\n",
    "cities = sorted(cities)\n",
    "print(cities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capturing all information in a list made of dictionary items\n",
    "information = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_city_link(city):\n",
    "    city = city.lower()\n",
    "    link = \"https://www.magicbricks.com/flats-for-rent-in-\" + city + \"-pppfr/page-1\"\n",
    "    return link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_page_link(city, page):\n",
    "    city = city.lower()\n",
    "    link = \"https://www.magicbricks.com/flats-for-rent-in-\" + city + \"-pppfr/page-\" + str(page)\n",
    "    return link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_of_pages(link):\n",
    "    html_text = requests.get(link).text\n",
    "    soup = BeautifulSoup(html_text, 'lxml')\n",
    "    number_of_pages = soup.find_all(\"a\", class_ = \"act\")\n",
    "    if number_of_pages:\n",
    "        last_page = number_of_pages[-1]\n",
    "        last_page = last_page.get('href')\n",
    "        if last_page == \"javascript:void(0)\":\n",
    "            last_page = 1\n",
    "        else:\n",
    "            last_page = int(last_page.split('-')[-1])\n",
    "    else:\n",
    "        last_page = 1\n",
    "    return last_page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_page_scraper(city, link, exclusivity):\n",
    "    html_text = requests.get(link).text\n",
    "    soup = BeautifulSoup(html_text, 'lxml')\n",
    "    rent = soup.find('div', class_ = \"p_price\")\n",
    "    if rent:\n",
    "        rent = \" \".join(rent.text.split())\n",
    "    else:\n",
    "        rent = \"\"\n",
    "#     print(rent)\n",
    "    name1 = soup.find(\"span\", class_=\"p_bhk\")\n",
    "    if name1:\n",
    "        name = \" \".join(name1.text.split())\n",
    "    else:\n",
    "        name = \"\"\n",
    "#     print(name)\n",
    "    location1 = soup.find(\"span\", class_ = \"p_text\")\n",
    "    if location1:\n",
    "        location = \" \".join(location1.text.split())\n",
    "    else:\n",
    "        location = \"\"\n",
    "#     print(location)\n",
    "    owner1 = soup.find(\"div\", class_=\"nameValue\")\n",
    "    if owner1:\n",
    "        owner = \" \".join(owner1.text.split())\n",
    "    else:\n",
    "        owner = \"\"\n",
    "#     print(owner)\n",
    "    posting_date1 = soup.find(\"div\", class_=\"postedOn\")\n",
    "    if posting_date1:\n",
    "        posting_date = \" \".join(posting_date1.text.split())\n",
    "    else:\n",
    "        posting_date = \"\"\n",
    "#     print(posting_date)\n",
    "    resulto = []\n",
    "    property_details = soup.find_all(\"div\", class_=\"p_infoColumn\")\n",
    "    if property_details:\n",
    "        for detail in property_details:\n",
    "            detail1 = detail.find(\"div\", class_ = \"p_title\")\n",
    "            detail1 = \" \".join(detail1.text.split())\n",
    "            detail2 = detail.find(\"div\", class_ = \"p_value\")\n",
    "            detail2 = \" \".join(detail2.text.split())\n",
    "    #         print(detail1)   \n",
    "    #         print(detail2)\n",
    "            result1 = \"\\n\".join([\": \".join(elem) for elem in zip(detail1.split('\\n'), detail2.split('\\n'))])\n",
    "    #         print(result1)\n",
    "            resulto.append(result1)\n",
    "#     print(resulto)  # some extra information came in carpets and square feet\n",
    "    resulty = []\n",
    "    description_box = soup.find(\"div\", class_=\"descriptionCont\")\n",
    "    amenities = description_box.find_all(\"div\", class_ = \"p_infoRow\")\n",
    "    description = description_box.find(\"div\", class_ = \"p_infoRow\")\n",
    "    if description:\n",
    "        description = \" \".join(description.text.split())\n",
    "#         print(description)\n",
    "    if amenities:\n",
    "        for detail in amenities:\n",
    "            detail1 = detail.find(\"div\", class_ = \"p_title\")\n",
    "            if detail1:\n",
    "                detail1 = \" \".join(detail1.text.split())\n",
    "            else:\n",
    "                continue\n",
    "            detail2 = detail.find(\"div\", class_ = \"p_value\")\n",
    "            if detail2:\n",
    "                detail2 = \" \".join(detail2.text.split())\n",
    "            result1 = \"\\n\".join([\": \".join(elem) for elem in zip(detail1.split('\\n'), detail2.split('\\n'))])\n",
    "            resulty.append(result1)\n",
    "    imagery = []\n",
    "    imagy = soup.find('img', attrs={'id': 'bigImageId'})\n",
    "    if imagy:\n",
    "        image = imagy.get('data-src')\n",
    "        image = image.replace('Photo_h400_w540', 'full_photo')\n",
    "        image = image.replace('_400_540', '')\n",
    "        image = image.replace('Photo_h300_w450', 'full_photo')\n",
    "        image = image.replace('_300_450', '')\n",
    "        imagery.append(image)\n",
    "#     print(resulty)\n",
    "#     images1 = soup.find(\"div\", class_=\"propertyImageSlider\")\n",
    "#     if images1:\n",
    "#         print('yo')\n",
    "#         images = images1.find_all(\"img\", class_ = \"swiper-lazy\")\n",
    "#         for image in images:\n",
    "#             image = image.get('data-src')\n",
    "#             imagesingle_page_scraper = image.replace('Photo_h400_w540', 'full_photo')\n",
    "#             image = image.replace('_400_540', '')\n",
    "#             imagery.append(image)\n",
    "    #         print(image)\n",
    "    room_item = {\n",
    "            \"city\": city,\n",
    "            \"living_type\": \"rent\",\n",
    "            \"exclusivity\": exclusivity,\n",
    "            \"name\": name,\n",
    "            \"owner\": owner,\n",
    "            \"link\": link,\n",
    "            \"posting_date\": posting_date,\n",
    "            \"location\": location,\n",
    "            \"rent_per_month\": rent,\n",
    "            \"image\": imagery,\n",
    "            # \"images_links\": imagery, # add using selenium click buttons\n",
    "            \"description\": description,\n",
    "            \"details\": resulto,\n",
    "            \"amenities\": resulty,\n",
    "        }\n",
    "    information.append(room_item)  \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for city in cities:\n",
    "    print(\"city: \" + city)\n",
    "    city_link = create_city_link(city)\n",
    "#     print(city_link)\n",
    "    all_pages = number_of_pages(city_link)\n",
    "    if all_pages >= 40:\n",
    "        all_pages = 30\n",
    "    print(\"number of pages: \" + str(all_pages))\n",
    "    for page in range(1, all_pages + 1):\n",
    "        link = create_page_link(city, page)\n",
    "    #             print(link)\n",
    "        data = requests.get(city_link).text\n",
    "        soupy = BeautifulSoup(data, 'lxml')\n",
    "    #     places1 = soupy.find_all('div', class_ = \"m-srp-card clearfix\")\n",
    "    #     places2 = soupy.find_all('div', class_ = \"m-srp-card verified-border clearfix\")\n",
    "    #     places3 = soupy.find_all('div', class_ = \"m-srp-card  clearfix\")\n",
    "        places = soupy.find_all('div', class_ = \"m-srp-card\")\n",
    "    #     print(len(places))\n",
    "        for place in places:\n",
    "            prime = place.find('button', class_ = \"m-srp-card__prime-btn\")\n",
    "            if prime:\n",
    "    #             print('skip')\n",
    "                continue\n",
    "            else:\n",
    "                if place.get('data-code'):\n",
    "                    place_link = place.get('data-code')[23:-19]\n",
    "    #                 print(place_link)\n",
    "                    exclusivity = place.find('div', class_ = \"m-srp-card__exonmag\")\n",
    "                    if exclusivity:\n",
    "                        exclusive = exclusivity.text\n",
    "                    else:\n",
    "                        exclusive = \"\"\n",
    "    #                 print(exclusive)\n",
    "                    try:\n",
    "                        single_page_scraper(city, place_link, exclusive)\n",
    "    #                     time.sleep(2)\n",
    "                    except Exception as e:\n",
    "                        print(place_link)\n",
    "                        print(e)\n",
    "                time.sleep(0.5)\n",
    "#             break\n",
    "    print(len(information))\n",
    "    print(city + \" done.\")\n",
    "#     break  # To check for one city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allahabad, Chandigarh, Nagpur, Noida\n",
    "# cities = cities[4:]\n",
    "cities = cities[11:]\n",
    "print(cities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"Magicbricks_rent_data_2.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
